{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6512e16-58bb-42bc-b4c2-1cb2a864a571",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c741b08-f4e6-4976-b00f-0bacdf7458b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"cifar100\" #\"places\" #\"imagenet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b786579f-6fd8-44a2-b483-c431a5dedffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "broden_labels = open(\"../data/concept_sets/broden_labels_clean.txt\", \"r\").read().split(\"\\n\")\n",
    "nouns = open(\"../data/concept_sets/nouns.txt\", \"r\").read().split(\"\\n\")\n",
    "\n",
    "if dataset == \"imagenet\":\n",
    "    imagenet_labels = open(\"../data/concept_sets/imagenet_labels_clean.txt\", \"r\").read().split(\"\\n\")\n",
    "    imagenet_superclasses = list(json.load(open(\"../data/concept_sets/imagenet_superclass_to_ids.json\", \"r\")).keys())\n",
    "    all_concepts = imagenet_labels + imagenet_superclasses + broden_labels + nouns\n",
    "\n",
    "if dataset == \"cifar100\":\n",
    "    cifar100_labels = open(\"../data/concept_sets/cifar100_labels_clean.txt\", \"r\").read().split(\"\\n\")\n",
    "    cifar100_superclasses = list(json.load(open(\"../data/concept_sets/cifar100_superclass_to_ids.json\", \"r\")).keys())\n",
    "    all_concepts = cifar100_labels + cifar100_superclasses + broden_labels + nouns\n",
    "\n",
    "elif dataset == \"places\":\n",
    "    places_labels = open(\"../data/concept_sets/places365_labels_clean.txt\", \"r\").read().split(\"\\n\")\n",
    "    all_concepts = places_labels + broden_labels + nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3278ecd5-eb3e-4984-9b30-5b7196975c91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8117\n",
      "7561 7561\n"
     ]
    }
   ],
   "source": [
    "print(len(all_concepts))\n",
    "new_concepts = []\n",
    "#remove duplicates while preserving order\n",
    "for concept in all_concepts:\n",
    "    if concept not in new_concepts:\n",
    "        new_concepts.append(concept)\n",
    "\n",
    "print(len(new_concepts), len(set(new_concepts)))\n",
    "\n",
    "with open(\"../data/concept_sets/combined_concepts_{}.txt\".format(dataset), \"w\") as f:\n",
    "    f.write(new_concepts[0])\n",
    "    for word in new_concepts[1:]:\n",
    "        try:\n",
    "            f.write(\"\\n\" + word)\n",
    "        except(UnicodeEncodeError):\n",
    "            print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb7f983-e3d2-40f9-bf12-e201b876fb9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#how broden labels were cleaned\n",
    "\n",
    "# labels = pd.read_csv('../data/broden1_224/label.csv')\n",
    "# labels = list(labels['name'])\n",
    "\n",
    "# new_labels = []\n",
    "# for label in labels:\n",
    "#     label = label.replace(\"-c\", \" color\")\n",
    "#     label = label.replace(\"_\", \" \")\n",
    "#     if \"-s\" in label:\n",
    "#         label = label.replace(\"-s\", \"\")\n",
    "#         if label in labels: #duplicate concept is already there\n",
    "#             label = label + \"(scene)\"\n",
    "#     label = label.replace(\"-\", \", \")\n",
    "    \n",
    "#         #only add scene if there's duplicates\n",
    "#     new_labels.append(label)\n",
    "# new_labels\n",
    "\n",
    "# with open(\"data/broden_labels_clean.txt\", \"w\") as f:\n",
    "#     f.write(new_labels[0])\n",
    "#     for label in new_labels[1:]:\n",
    "#         f.write(\"\\n{}\".format(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f167ca-c20a-4e9a-b97a-d460ebec8e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "#how places class names were cleaned\n",
    "\n",
    "# labels = open('data/categories_places365.txt', \"r\").read().split(\"\\n\")\n",
    "\n",
    "# new_labels = []\n",
    "# for label in labels:\n",
    "#     label = label[3:]\n",
    "#     label = label.split(\" \")[0]\n",
    "#     label = label.replace(\"_\", \" \")\n",
    "#     label = label.replace(\"/\", \", \")\n",
    "#     new_labels.append(label)\n",
    "# new_labels\n",
    "# print(new_labels)\n",
    "# with open(\"data/places365_labels_clean.txt\", \"w\") as f:\n",
    "#     f.write(new_labels[0])\n",
    "#     for label in new_labels[1:]:\n",
    "#         f.write(\"\\n{}\".format(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ad07a9-f417-409d-9f38-3877f2539546",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
