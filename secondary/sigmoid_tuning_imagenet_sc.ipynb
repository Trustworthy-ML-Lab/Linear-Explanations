{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79c84c33-4a5a-4c61-81ef-36e7e26b4f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "#change virtually to parent dir\n",
    "os.chdir(\"..\")\n",
    "import torch\n",
    "\n",
    "import open_clip\n",
    "import data_utils\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8abfae73-9acf-41da-b4eb-2ff3305e43bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\"\n",
    "dataset_name = \"imagenet_val\"\n",
    "batch_size = 128\n",
    "save_dir = 'saved_activations'\n",
    "clip_name = \"ViT-L-16-SigLIP-384\"#\"ViT-SO400M-14-SigLIP-384\"\n",
    "clip_model, _, clip_preprocess = open_clip.create_model_and_transforms(clip_name.split(\"_\")[-1], pretrained=utils.CN_TO_CHECKPOINT[clip_name],\n",
    "                                                                       device=device)\n",
    "tokenizer = open_clip.get_tokenizer(clip_name.split(\"_\")[-1])\n",
    "\n",
    "clip_data = data_utils.get_data(dataset_name, clip_preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6174a1ea-415b-4566-89eb-6e14aa2fca8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/concept_sets/imagenet_labels_clean.txt', 'r') as f: \n",
    "    class_names = (f.read()).split('\\n')\n",
    "\n",
    "clip_save_name = \"{}/{}_{}.pt\".format(save_dir, dataset_name, clip_name.replace('/', ''))\n",
    "utils.save_clip_image_features(clip_model, clip_data, clip_save_name, batch_size, device)\n",
    "clip_image_features = torch.load(clip_save_name, map_location=device).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f4509ae-259e-40bc-b606-6d780458c785",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entity 1000\n",
      "physical entity 997\n",
      "object 958\n",
      "whole 949\n",
      "organism 410\n",
      "animal 398\n",
      "vertebrate 337\n",
      "artifact 522\n",
      "instrumentality 358\n",
      "torch.Size([50000, 1000]) torch.Size([50000, 391])\n"
     ]
    }
   ],
   "source": [
    "num_classes = max(clip_data.targets) + 1\n",
    "\n",
    "# Convert to one-hot encoding\n",
    "one_hot_labels = torch.zeros((len(clip_data.targets), num_classes))\n",
    "one_hot_labels[torch.arange(len(clip_data.targets)), clip_data.targets] = 1\n",
    "one_hot_labels = one_hot_labels.to(device)\n",
    "\n",
    "with open('data/concept_sets/imagenet_superclass_to_ids.json', 'r') as f:\n",
    "    superclass_to_id = json.load(f)\n",
    "\n",
    "new_labels = []\n",
    "for sclass in superclass_to_id.keys():\n",
    "    subclasses = superclass_to_id[sclass]\n",
    "    #not using subclasses that cover more than 30% of the data\n",
    "    if len(subclasses) > 300:\n",
    "        print(sclass, len(subclasses))\n",
    "        continue\n",
    "    class_names.append(sclass.replace(\"_\", \" \"))\n",
    "    new_labels.append(torch.sum(torch.stack([one_hot_labels[:, i] for i in subclasses], dim=0), dim=0))\n",
    "new_labels = torch.stack(new_labels, dim=1)\n",
    "print(one_hot_labels.shape, new_labels.shape)\n",
    "one_hot_labels = torch.cat([one_hot_labels, new_labels], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b86f23a-8508-4769-b7de-2fef4c0d4bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "clip_text_features = utils.get_clip_text_features(clip_model, tokenizer(class_names).to(device)).float()\n",
    "with torch.no_grad():\n",
    "    clip_image_features /= clip_image_features.norm(dim=-1, keepdim=True)\n",
    "    clip_text_features /= clip_text_features.norm(dim=-1, keepdim=True)\n",
    "    clip_feats = (clip_image_features @ clip_text_features.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9025df2f-7561-4205-9ae6-0bca26b28024",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loss(a=1, b=0):\n",
    "    loss_fn = torch.nn.BCELoss()\n",
    "    with torch.no_grad():\n",
    "        outs = torch.sigmoid(a*(clip_feats+b))\n",
    "        loss = loss_fn(outs, one_hot_labels)\n",
    "        return loss.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "49307ac5-f34f-4801-878f-52808d233b3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a=0.10, b=-1.00, loss=0.64293\n",
      "a=0.25, b=-1.00, loss=0.57265\n",
      "a=0.50, b=-1.00, loss=0.46869\n",
      "a=0.75, b=-1.00, loss=0.38047\n",
      "a=1.00, b=-1.00, loss=0.30676\n",
      "a=2.00, b=-1.00, loss=0.12546\n",
      "a=4.00, b=-1.00, loss=0.03004\n",
      "a=6.00, b=-1.00, loss=0.02347\n",
      "a=6.00, b=-0.99, loss=0.02337\n",
      "a=6.00, b=-0.98, loss=0.02328\n",
      "a=6.00, b=-0.97, loss=0.02319\n",
      "a=6.00, b=-0.96, loss=0.02312\n",
      "a=6.00, b=-0.95, loss=0.02305\n",
      "a=6.00, b=-0.94, loss=0.02299\n",
      "a=6.00, b=-0.93, loss=0.02295\n",
      "a=6.00, b=-0.92, loss=0.02291\n",
      "a=6.00, b=-0.91, loss=0.02289\n",
      "a=6.00, b=-0.90, loss=0.02288\n",
      "a=8.00, b=-0.73, loss=0.02276\n",
      "a=8.00, b=-0.72, loss=0.02265\n",
      "a=8.00, b=-0.71, loss=0.02255\n",
      "a=8.00, b=-0.70, loss=0.02246\n",
      "a=8.00, b=-0.69, loss=0.02240\n",
      "a=8.00, b=-0.68, loss=0.02235\n",
      "a=8.00, b=-0.67, loss=0.02233\n",
      "a=8.00, b=-0.66, loss=0.02233\n",
      "a=10.00, b=-0.58, loss=0.02225\n",
      "a=10.00, b=-0.57, loss=0.02211\n",
      "a=10.00, b=-0.56, loss=0.02199\n",
      "a=10.00, b=-0.55, loss=0.02189\n",
      "a=10.00, b=-0.54, loss=0.02183\n",
      "a=10.00, b=-0.53, loss=0.02180\n",
      "a=12.00, b=-0.48, loss=0.02176\n",
      "a=12.00, b=-0.47, loss=0.02158\n",
      "a=12.00, b=-0.46, loss=0.02144\n",
      "a=12.00, b=-0.45, loss=0.02134\n",
      "a=12.00, b=-0.44, loss=0.02129\n",
      "a=12.00, b=-0.43, loss=0.02128\n",
      "a=14.00, b=-0.40, loss=0.02109\n",
      "a=14.00, b=-0.39, loss=0.02093\n",
      "a=14.00, b=-0.38, loss=0.02082\n",
      "a=14.00, b=-0.37, loss=0.02078\n",
      "a=16.00, b=-0.35, loss=0.02067\n",
      "a=16.00, b=-0.34, loss=0.02047\n",
      "a=16.00, b=-0.33, loss=0.02034\n",
      "a=16.00, b=-0.32, loss=0.02030\n",
      "a=18.00, b=-0.31, loss=0.02023\n",
      "a=18.00, b=-0.30, loss=0.02001\n",
      "a=18.00, b=-0.29, loss=0.01987\n",
      "a=18.00, b=-0.28, loss=0.01984\n",
      "a=20.00, b=-0.27, loss=0.01960\n",
      "a=20.00, b=-0.26, loss=0.01943\n",
      "a=20.00, b=-0.25, loss=0.01939\n",
      "a=22.00, b=-0.25, loss=0.01934\n",
      "a=22.00, b=-0.24, loss=0.01908\n",
      "a=22.00, b=-0.23, loss=0.01897\n",
      "a=24.00, b=-0.22, loss=0.01870\n",
      "a=24.00, b=-0.21, loss=0.01856\n",
      "a=26.00, b=-0.21, loss=0.01854\n",
      "a=26.00, b=-0.20, loss=0.01826\n",
      "a=26.00, b=-0.19, loss=0.01818\n",
      "a=28.00, b=-0.19, loss=0.01802\n",
      "a=28.00, b=-0.18, loss=0.01782\n",
      "a=30.00, b=-0.18, loss=0.01778\n",
      "a=30.00, b=-0.17, loss=0.01750\n",
      "a=32.00, b=-0.16, loss=0.01720\n",
      "a=32.00, b=-0.15, loss=0.01720\n",
      "a=34.00, b=-0.15, loss=0.01689\n",
      "a=36.00, b=-0.15, loss=0.01688\n",
      "a=36.00, b=-0.14, loss=0.01660\n",
      "a=38.00, b=-0.14, loss=0.01653\n",
      "a=38.00, b=-0.13, loss=0.01634\n",
      "a=40.00, b=-0.13, loss=0.01619\n",
      "a=42.00, b=-0.12, loss=0.01592\n",
      "a=44.00, b=-0.12, loss=0.01584\n",
      "a=44.00, b=-0.11, loss=0.01583\n",
      "a=46.00, b=-0.11, loss=0.01560\n",
      "a=48.00, b=-0.11, loss=0.01552\n",
      "a=50.00, b=-0.10, loss=0.01542\n",
      "a=52.00, b=-0.10, loss=0.01529\n",
      "a=54.00, b=-0.10, loss=0.01527\n",
      "a=58.00, b=-0.09, loss=0.01520\n",
      "a=60.00, b=-0.09, loss=0.01517\n"
     ]
    }
   ],
   "source": [
    "a_values = [0.1, 0.25, 0.5, 0.75, 1]+[2*n for n in range(76)]\n",
    "b_values = [0.01*n for n in range(-100, 101)]\n",
    "\n",
    "best_loss = torch.inf\n",
    "for a in a_values:\n",
    "    for b in b_values:\n",
    "        loss = get_loss(a, b)\n",
    "        if loss < best_loss:\n",
    "            best_loss = loss\n",
    "            print(\"a={:.2f}, b={:.2f}, loss={:.5f}\".format(a, b, loss))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
